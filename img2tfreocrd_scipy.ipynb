{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nakyilkim\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "### img -> tf record withot pickling\n",
    "\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from PIL import Image\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import skimage.io as io\n",
    "import tensorflow as tf\n",
    "\n",
    "from tqdm import tqdm\n",
    "from dltk.io.preprocessing import *\n",
    "import scipy.ndimage\n",
    "\n",
    "\n",
    "import pickle\n",
    "\n",
    "root = 'D:\\segmentiation/'\n",
    "ct_set = os.path.join(root,'ct_train_test/ct_train/')\n",
    "mr_set = os.path.join(root,'mr_train_test/mr_train/')\n",
    "filenames = os.listdir(ct_set)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pickle_iter(path):\n",
    "    f = open(path, 'rb')\n",
    "    unpickler = pickle.Unpickler(f)\n",
    "    try:\n",
    "        for i in range(9999999999):\n",
    "            yield unpickler.load()\n",
    "    except:\n",
    "        f.close()\n",
    "        print('pickle generator created')\n",
    "\n",
    "        \n",
    "def pad3d(array):\n",
    "    height = array.shape[0]\n",
    "    depth = array.shape[2]\n",
    "    \n",
    "    if (height - depth) % 2 :\n",
    "        pad_front = int((height + 1 - depth) / 2)\n",
    "        pad_back = int((height - 1 - depth) / 2)\n",
    "    else:\n",
    "        pad_front = pad_back = int((height - depth) / 2)\n",
    "    \n",
    "    npad = ((0,0),(0,0),(pad_front,pad_back))\n",
    "    array_padding = np.pad(array, npad, 'constant', constant_values=(0))\n",
    "    array_padding[array_padding<0] = 0\n",
    "    \n",
    "    return array_padding\n",
    "\n",
    "\n",
    "def image_preprocess(image, new_size, mask=False):\n",
    "    assert np.sum(image.shape==image.shape[0])!=3    \n",
    "    \n",
    "    ratio = new_size / image.shape[0]\n",
    "    \n",
    "    image = scipy.ndimage.zoom(image, zoom=ratio, order=0)\n",
    "\n",
    "    if mask:\n",
    "        channel = 7 + 1 #background\n",
    "        image = image.reshape(-1)\n",
    "        image = label_encoder.fit_transform(image)\n",
    "        \n",
    "        \n",
    "        print(\"image shape\",image.shape)\n",
    "        print(\"unique value\", np.unique(image))\n",
    "        \n",
    "        \n",
    "        image = to_categorical(image, class_num)\n",
    "    else:\n",
    "        channel = 1\n",
    "    # reshape to raw shape\n",
    "    image = image.reshape((new_size,)*3 + (channel,))\n",
    "\n",
    "    return image\n",
    "\n",
    "def nii_loader(path,file_name):\n",
    "    file_path =  os.path.join(path,file_name)\n",
    "    fn = os.listdir(file_path)\n",
    "    image = (nib.load(file_path + '/' + fn[0]))\n",
    "    return image\n",
    "\n",
    "\n",
    "def _bytes_feature(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "\n",
    "def _int64_feature(value):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "def write_image_annotation_pairs_to_tfrecord_from_gen(generator, tfrecords_filename):\n",
    "    \"\"\"Writes given image/annotation pairs to the tfrecords file.\n",
    "    The function reads each image/anno'tation pair given filenames\n",
    "    of image and respective annotation and writes it to the tfrecord\n",
    "    file.\n",
    "    Parameters\n",
    "    ----------\n",
    "    filename_pairs : array of tuples (img_filepath, annotation_filepath)\n",
    "        Array of tuples of image/annotation filenames\n",
    "    tfrecords_filename : string\n",
    "        Tfrecords filename to write the image/annotation pairs\n",
    "    \"\"\"\n",
    "    options = tf.python_io.TFRecordOptions(tf.python_io.TFRecordCompressionType.GZIP)\n",
    "    writer = tf.python_io.TFRecordWriter(tfrecords_filename,options=options)\n",
    "\n",
    "    #for img_path, annotation_path in filename_pairs:\n",
    "\n",
    "\n",
    "\n",
    "    for i, record in enumerate(generator):\n",
    "        print(i)\n",
    "\n",
    "\n",
    "\n",
    "        #img = np.array(Image.open(img_path))\n",
    "\n",
    "        #annotation = np.array(Image.open(annotation_path))\n",
    "\n",
    "        # Unomment this one when working with surgical data\n",
    "        # annotation = annotation[:, :, 0]\n",
    "\n",
    "        # The reason to store image sizes was demonstrated\n",
    "        # in the previous example -- we have to know sizes\n",
    "        # of images to later read raw serialized string,\n",
    "        \n",
    "        # convert to 1d array and convert to respective\n",
    "        # shape that image used to have.\n",
    "        #height = img.shape[0] \n",
    "    \n",
    "        img = record[0]\n",
    "        annotation = record[0]\n",
    "        \n",
    "        print(img.shape)\n",
    "\n",
    "\n",
    "        height = img.shape[0] \n",
    "\n",
    "        #width = img.shape[1]\n",
    "        width = img.shape[1] \n",
    "\n",
    "\n",
    "        #add depth \n",
    "        depth = img.shape[2]\n",
    "        #print(depth)\n",
    "        #print(img[0].shape) #288,288,140 \n",
    "\n",
    "\n",
    "        #img_raw = img.tostring()\n",
    "        img_raw=img.tostring()\n",
    "\n",
    "        ## 여기서 에러\n",
    "        print(\"img shape: {}, img_raw shape: {}\".format(img.shape,len(img_raw)))\n",
    "\n",
    "        ## 여기서 에러\n",
    "        annotation_raw = annotation.tostring()\n",
    "        print(\"annotation_ shape: {}, annotation_raw shape: {}\".format(annotation.shape,len(annotation_raw)))\n",
    "\n",
    "        #print(annotation[1].shape)\n",
    "        #print(annotation[2].shape)\n",
    "\n",
    "\n",
    "        #print(annotation_raw)\n",
    "        #annotation_raw = annotation.tostring()\n",
    "\n",
    "        example = tf.train.Example(features=tf.train.Features(feature={\n",
    "            'height': _int64_feature(height),\n",
    "            'width': _int64_feature(width),\n",
    "            'depth': _int64_feature(depth), \n",
    "            'image_raw': _bytes_feature(img_raw),\n",
    "            'mask_raw': _bytes_feature(annotation_raw)}))\n",
    "\n",
    "        writer.write(example.SerializeToString())\n",
    "\n",
    "    writer.close()\n",
    "    \n",
    "def write_image_annotation_pairs_to_tfrecord_from_listitr(pickle_itr_list, tfrecords_filename):\n",
    "    \"\"\"Writes given image/annotation pairs to the tfrecords file.\n",
    "    The function reads each image/anno'tation pair given filenames\n",
    "    of image and respective annotation and writes it to the tfrecord\n",
    "    file.\n",
    "    Parameters\n",
    "    ----------\n",
    "    filename_pairs : array of tuples (img_filepath, annotation_filepath)\n",
    "        Array of tuples of image/annotation filenames\n",
    "    tfrecords_filename : string\n",
    "        Tfrecords filename to write the image/annotation pairs\n",
    "    \"\"\"\n",
    "    options = tf.python_io.TFRecordOptions(tf.python_io.TFRecordCompressionType.GZIP)\n",
    "    writer = tf.python_io.TFRecordWriter(tfrecords_filename,options=options)\n",
    "\n",
    "    #for img_path, annotation_path in filename_pairs:\n",
    "    \n",
    "    \n",
    "    for pickle_itr in pickle_itr_list:\n",
    "\n",
    "        for i,record in enumerate(pickle_itr):\n",
    "            print(i)\n",
    "            print(record.keys())\n",
    "\n",
    "            img = record['image']\n",
    "            annotation = record['label']\n",
    "\n",
    "            #img = np.array(Image.open(img_path))\n",
    "\n",
    "            #annotation = np.array(Image.open(annotation_path))\n",
    "\n",
    "            # Unomment this one when working with surgical data\n",
    "            # annotation = annotation[:, :, 0]\n",
    "\n",
    "            # The reason to store image sizes was demonstrated\n",
    "            # in the previous example -- we have to know sizes\n",
    "            # of images to later read raw serialized string,\n",
    "            # convert to 1d array and convert to respective\n",
    "            # shape that image used to have.\n",
    "            #height = img.shape[0] \n",
    "\n",
    "            print(img.shape)\n",
    "            ##### img = img.reshape()\n",
    "            \n",
    "            \n",
    "            height = img.shape[0] \n",
    "\n",
    "            #width = img.shape[1]\n",
    "            width = img.shape[1] \n",
    "\n",
    "\n",
    "            #add depth \n",
    "            depth = img.shape[2]\n",
    "            #print(depth)\n",
    "            #print(img[0].shape) #288,288,140 \n",
    "\n",
    "\n",
    "            #img_raw = img.tostring()\n",
    "            img_raw=img.tostring()\n",
    "\n",
    "            ## 여기서 에러\n",
    "            print(\"img shape: {}, img_raw shape: {}\".format(img.shape,len(img_raw)))\n",
    "\n",
    "            ## 여기서 에러\n",
    "            annotation_raw = annotation.tostring()\n",
    "            print(\"annotation_ shape: {}, annotation_raw shape: {}\".format(annotation.shape,len(annotation_raw)))\n",
    "\n",
    "            #print(annotation[1].shape)\n",
    "            #print(annotation[2].shape)\n",
    "\n",
    "\n",
    "            #print(annotation_raw)\n",
    "            #annotation_raw = annotation.tostring()\n",
    "\n",
    "            example = tf.train.Example(features=tf.train.Features(feature={\n",
    "                'height': _int64_feature(height),\n",
    "                'width': _int64_feature(width),\n",
    "                'depth': _int64_feature(depth), \n",
    "                'image_raw': _bytes_feature(img_raw),\n",
    "                'mask_raw': _bytes_feature(annotation_raw)}))\n",
    "\n",
    "            writer.write(example.SerializeToString())\n",
    "\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_list = []\n",
    "filenames = os.listdir(ct_set)\n",
    "\n",
    "for i in filenames:\n",
    "    if i[:13] not in name_list:\n",
    "        name_list.append(i[:13])\n",
    "        \n",
    "total_list = []\n",
    "for i in name_list:\n",
    "    temp_name = i\n",
    "    temp_image = i+'_image.nii'\n",
    "    temp_label = i+'_label.nii'\n",
    "    total_list.append({'name' : temp_name,'image':temp_image,'label':temp_label})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_tfrecord_write_itr(path,itr):\n",
    "    for record in tqdm(itr):\n",
    "        file_name = record['name']\n",
    "        img_fname = record['image']\n",
    "        label_fname = record['label']\n",
    "        \n",
    "        img = nii_loader(path,img_fname)\n",
    "        lab = nii_loader(path, label_fname)\n",
    "        \n",
    "        print(\"Image Shape\",img.get_data().shape,)\n",
    "        \n",
    "        img = pad3d(img.get_data())\n",
    "        img = image_preprocess(img,new_size=256)\n",
    "        \n",
    "        lab = pad3d(lab.get_data())\n",
    "        lab = image_preprocess(lab,new_size=256,mask=True)\n",
    "        \n",
    "        yield img, lab\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                                                           | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Shape (512, 512, 363)\n",
      "image shape (16777216,)\n",
      "unique value [0 1 2 3 4 5 6 7]\n",
      "0\n",
      "(256, 256, 256, 1)\n",
      "img shape: (256, 256, 256, 1), img_raw shape: 134217728\n",
      "annotation_ shape: (256, 256, 256, 1), annotation_raw shape: 134217728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  5%|████▏                                                                              | 1/20 [00:35<11:11, 35.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Shape (512, 512, 239)\n",
      "image shape (16777216,)\n",
      "unique value [0 1 2 3 4 5 6 7]\n",
      "1\n",
      "(256, 256, 256, 1)\n",
      "img shape: (256, 256, 256, 1), img_raw shape: 134217728\n",
      "annotation_ shape: (256, 256, 256, 1), annotation_raw shape: 134217728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 10%|████████▎                                                                          | 2/20 [00:57<09:26, 31.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Shape (512, 512, 298)\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-83-3df11965f506>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mlabel_encoder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLabelEncoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mclass_num\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mwrite_image_annotation_pairs_to_tfrecord_from_gen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreprocess_gen\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtfrecords_filename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-79-b76116b4de79>\u001b[0m in \u001b[0;36mwrite_image_annotation_pairs_to_tfrecord_from_gen\u001b[1;34m(generator, tfrecords_filename)\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecord\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-81-5a2e90506fd4>\u001b[0m in \u001b[0;36mpre_process_tfrecord_write_itr\u001b[1;34m(path, itr)\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Image Shape\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpad3d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m         \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage_preprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnew_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m256\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-79-b76116b4de79>\u001b[0m in \u001b[0;36mpad3d\u001b[1;34m(array)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mnpad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpad_front\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpad_back\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0marray_padding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnpad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'constant'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconstant_values\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[0marray_padding\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0marray_padding\u001b[0m\u001b[1;33m<\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\lib\\arraypad.py\u001b[0m in \u001b[0;36mpad\u001b[1;34m(array, pad_width, mode, **kwargs)\u001b[0m\n\u001b[0;32m   1274\u001b[0m                 \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpad_width\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'constant_values'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1275\u001b[0m             \u001b[0mnewmat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_prepend_const\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnewmat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpad_before\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbefore_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1276\u001b[1;33m             \u001b[0mnewmat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_append_const\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnewmat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpad_after\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mafter_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1277\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1278\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'edge'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\lib\\arraypad.py\u001b[0m in \u001b[0;36m_append_const\u001b[1;34m(arr, pad_amt, val, axis)\u001b[0m\n\u001b[0;32m    159\u001b[0m     padshape = tuple(x if i != axis else pad_amt\n\u001b[0;32m    160\u001b[0m                      for (i, x) in enumerate(arr.shape))\n\u001b[1;32m--> 161\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_do_append\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpadshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    162\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\lib\\arraypad.py\u001b[0m in \u001b[0;36m_do_append\u001b[1;34m(arr, pad_chunk, axis)\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_do_append\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpad_chunk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m     return np.concatenate(\n\u001b[1;32m--> 103\u001b[1;33m         (arr, pad_chunk.astype(arr.dtype, copy=False)), axis=axis)\n\u001b[0m\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## Pickling 안하면 메모리 에러 ;;\n",
    "## 성능 좋으면 여기만 돌리면 됨\n",
    "\n",
    "preprocess_gen = pre_process_tfrecord_write_itr(ct_set,total_list)\n",
    "tfrecords_filename = r\"D:\\segmentiation\\scipy_tfrecord_compression.tfrecord\"\n",
    "\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "class_num=7+1\n",
    "write_image_annotation_pairs_to_tfrecord_from_gen(preprocess_gen,tfrecords_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'ct_train_1001',\n",
       "  'image': 'ct_train_1001_image.nii',\n",
       "  'label': 'ct_train_1001_label.nii'},\n",
       " {'name': 'ct_train_1002',\n",
       "  'image': 'ct_train_1002_image.nii',\n",
       "  'label': 'ct_train_1002_label.nii'},\n",
       " {'name': 'ct_train_1003',\n",
       "  'image': 'ct_train_1003_image.nii',\n",
       "  'label': 'ct_train_1003_label.nii'},\n",
       " {'name': 'ct_train_1004',\n",
       "  'image': 'ct_train_1004_image.nii',\n",
       "  'label': 'ct_train_1004_label.nii'},\n",
       " {'name': 'ct_train_1005',\n",
       "  'image': 'ct_train_1005_image.nii',\n",
       "  'label': 'ct_train_1005_label.nii'},\n",
       " {'name': 'ct_train_1006',\n",
       "  'image': 'ct_train_1006_image.nii',\n",
       "  'label': 'ct_train_1006_label.nii'},\n",
       " {'name': 'ct_train_1007',\n",
       "  'image': 'ct_train_1007_image.nii',\n",
       "  'label': 'ct_train_1007_label.nii'},\n",
       " {'name': 'ct_train_1008',\n",
       "  'image': 'ct_train_1008_image.nii',\n",
       "  'label': 'ct_train_1008_label.nii'},\n",
       " {'name': 'ct_train_1009',\n",
       "  'image': 'ct_train_1009_image.nii',\n",
       "  'label': 'ct_train_1009_label.nii'},\n",
       " {'name': 'ct_train_1010',\n",
       "  'image': 'ct_train_1010_image.nii',\n",
       "  'label': 'ct_train_1010_label.nii'},\n",
       " {'name': 'ct_train_1011',\n",
       "  'image': 'ct_train_1011_image.nii',\n",
       "  'label': 'ct_train_1011_label.nii'},\n",
       " {'name': 'ct_train_1012',\n",
       "  'image': 'ct_train_1012_image.nii',\n",
       "  'label': 'ct_train_1012_label.nii'},\n",
       " {'name': 'ct_train_1013',\n",
       "  'image': 'ct_train_1013_image.nii',\n",
       "  'label': 'ct_train_1013_label.nii'},\n",
       " {'name': 'ct_train_1014',\n",
       "  'image': 'ct_train_1014_image.nii',\n",
       "  'label': 'ct_train_1014_label.nii'},\n",
       " {'name': 'ct_train_1015',\n",
       "  'image': 'ct_train_1015_image.nii',\n",
       "  'label': 'ct_train_1015_label.nii'},\n",
       " {'name': 'ct_train_1016',\n",
       "  'image': 'ct_train_1016_image.nii',\n",
       "  'label': 'ct_train_1016_label.nii'},\n",
       " {'name': 'ct_train_1017',\n",
       "  'image': 'ct_train_1017_image.nii',\n",
       "  'label': 'ct_train_1017_label.nii'},\n",
       " {'name': 'ct_train_1018',\n",
       "  'image': 'ct_train_1018_image.nii',\n",
       "  'label': 'ct_train_1018_label.nii'},\n",
       " {'name': 'ct_train_1019',\n",
       "  'image': 'ct_train_1019_image.nii',\n",
       "  'label': 'ct_train_1019_label.nii'},\n",
       " {'name': 'ct_train_1020',\n",
       "  'image': 'ct_train_1020_image.nii',\n",
       "  'label': 'ct_train_1020_label.nii'}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|                                                                                           | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image shape (16777216,)\n",
      "unique value [0 1 2 3 4 5 6 7]\n",
      "Start MASKING==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  5%|████▏                                                                              | 1/20 [00:35<11:17, 35.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image shape (16777216,)\n",
      "unique value [0 1 2 3 4 5 6 7]\n",
      "Start MASKING==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 10%|████████▎                                                                          | 2/20 [01:11<10:42, 35.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image shape (16777216,)\n",
      "unique value [0 1 2 3 4 5 6 7]\n",
      "Start MASKING==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 15%|████████████▍                                                                      | 3/20 [01:51<10:29, 37.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image shape (16777216,)\n",
      "unique value [0 1 2 3 4 5 6 7]\n",
      "Start MASKING==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 20%|████████████████▌                                                                  | 4/20 [02:25<09:38, 36.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image shape (16777216,)\n",
      "unique value [0 1 2 3 4 5 6 7]\n",
      "Start MASKING==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 25%|████████████████████▊                                                              | 5/20 [02:58<08:48, 35.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image shape (16777216,)\n",
      "unique value [0 1 2 3 4 5 6 7]\n",
      "Start MASKING==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 30%|████████████████████████▉                                                          | 6/20 [03:35<08:18, 35.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image shape (16777216,)\n",
      "unique value [0 1 2 3 4 5 6 7]\n",
      "Start MASKING==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 35%|█████████████████████████████                                                      | 7/20 [04:14<07:55, 36.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image shape (16777216,)\n",
      "unique value [0 1 2 3 4 5 6 7]\n",
      "Start MASKING==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 40%|█████████████████████████████████▏                                                 | 8/20 [04:48<07:09, 35.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image shape (16777216,)\n",
      "unique value [0 1 2 3 4 5 6 7]\n",
      "Start MASKING==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 45%|█████████████████████████████████████▎                                             | 9/20 [05:28<06:48, 37.14s/it]"
     ]
    }
   ],
   "source": [
    "outpath = r\"D:\\segmentiation\\scipy_pickle_test0.pkl\"\n",
    "memory_error_list = []\n",
    "cnt = 0\n",
    "\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "class_num=7+1\n",
    "## Making padded image\n",
    "\n",
    "todolist = [i for i in total_list]\n",
    "\n",
    "\n",
    "\n",
    "with open(outpath,\"wb\") as f:\n",
    "    pickler = pickle.Pickler(f)\n",
    "    for  record in tqdm(todolist):\n",
    "\n",
    "\n",
    "        try :\n",
    "\n",
    "            file_name = record['name']\n",
    "            img_fname = record['image']\n",
    "            label_fname = record['label']\n",
    "\n",
    "\n",
    "\n",
    "            # nii load // 이 결과가가 원래 결과랑 같은 지 확인 하자\n",
    "            img = nii_loader(ct_set,img_fname)\n",
    "            lab = nii_loader(ct_set, label_fname)\n",
    "\n",
    "\n",
    "            img = pad3d(img.get_data())\n",
    "            img = image_preprocess(img,new_size=256)\n",
    "\n",
    "            lab = pad3d(lab.get_data())\n",
    "            lab = image_preprocess(lab,new_size=256,mask=True)\n",
    "\n",
    "\n",
    "\n",
    "            print(\"Start MASKING\"+\"=====\"*10)\n",
    "\n",
    "            List = {'filename':file_name,'image': img, 'label':  lab}\n",
    "            pickler.dump(List)\n",
    "\n",
    "            del file_name, img_fname, label_fname, img, lab\n",
    "            \n",
    "            print(\"Dumping\",cnt)\n",
    "            cnt += 1\n",
    "\n",
    "        except MemoryError:\n",
    "            print(\"Memory Error\")\n",
    "            todolist = total_list[cnt:]\n",
    "            break\n",
    "\n",
    "outpath = outpath[:-5] + str(int(outpath[-5]) + 1) + str(\".pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  0%|                                                                                           | 0/11 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image shape (16777216,)\n",
      "unique value [0 1 2 3 4 5 6 7]\n",
      "Start MASKING==================================================\n",
      "Dumping 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  9%|███████▌                                                                           | 1/11 [00:33<05:36, 33.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image shape (16777216,)\n",
      "unique value [0 1 2 3 4 5 6 7]\n",
      "Start MASKING==================================================\n",
      "Dumping 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 18%|███████████████                                                                    | 2/11 [01:09<05:09, 34.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image shape (16777216,)\n",
      "unique value [0 1 2 3 4 5 6 7]\n",
      "Start MASKING==================================================\n",
      "Dumping 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 27%|██████████████████████▋                                                            | 3/11 [01:42<04:32, 34.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image shape (16777216,)\n",
      "unique value [0 1 2 3 4 5 6 7]\n",
      "Start MASKING==================================================\n",
      "Dumping 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 36%|██████████████████████████████▏                                                    | 4/11 [02:20<04:04, 34.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image shape (16777216,)\n",
      "unique value [0 1 2 3 4 5 6 7]\n",
      "Start MASKING==================================================\n",
      "Dumping 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 45%|█████████████████████████████████████▋                                             | 5/11 [03:02<03:43, 37.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image shape (16777216,)\n",
      "unique value [0 1 2 3 4 5 6 7]\n",
      "Start MASKING==================================================\n",
      "Dumping 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 55%|█████████████████████████████████████████████▎                                     | 6/11 [03:42<03:09, 37.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image shape (16777216,)\n",
      "unique value [0 1 2 3 4 5 6 7]\n",
      "Start MASKING==================================================\n",
      "Dumping 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 64%|████████████████████████████████████████████████████▊                              | 7/11 [04:23<02:36, 39.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image shape (16777216,)\n",
      "unique value [0 1 2 3 4 5 6 7]\n",
      "Start MASKING==================================================\n",
      "Dumping 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 73%|████████████████████████████████████████████████████████████▎                      | 8/11 [05:03<01:57, 39.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image shape (16777216,)\n",
      "unique value [0 1 2 3 4 5 6 7]\n",
      "Start MASKING==================================================\n",
      "Dumping 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 82%|███████████████████████████████████████████████████████████████████▉               | 9/11 [05:36<01:14, 37.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory Error\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: '.'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-115999b7992e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     40\u001b[0m             \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m \u001b[0moutpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutpath\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutpath\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\".pkl\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: invalid literal for int() with base 10: '.'"
     ]
    }
   ],
   "source": [
    "with open(outpath,\"wb\") as f:\n",
    "    pickler = pickle.Pickler(f)\n",
    "    for  record in tqdm(todolist):\n",
    "\n",
    "\n",
    "        try :\n",
    "\n",
    "            file_name = record['name']\n",
    "            img_fname = record['image']\n",
    "            label_fname = record['label']\n",
    "\n",
    "\n",
    "\n",
    "            # nii load // 이 결과가가 원래 결과랑 같은 지 확인 하자\n",
    "            img = nii_loader(ct_set,img_fname)\n",
    "            lab = nii_loader(ct_set, label_fname)\n",
    "\n",
    "\n",
    "            img = pad3d(img.get_data())\n",
    "            img = image_preprocess(img,new_size=256)\n",
    "\n",
    "            lab = pad3d(lab.get_data())\n",
    "            lab = image_preprocess(lab,new_size=256,mask=True)\n",
    "\n",
    "\n",
    "\n",
    "            print(\"Start MASKING\"+\"=====\"*10)\n",
    "\n",
    "            List = {'filename':file_name,'image': img, 'label':  lab}\n",
    "            pickler.dump(List)\n",
    "\n",
    "            del file_name, img_fname, label_fname, img, lab\n",
    "            \n",
    "            print(\"Dumping\",cnt)\n",
    "            cnt += 1\n",
    "\n",
    "        except MemoryError:\n",
    "            print(\"Memory Error\")\n",
    "            todolist = total_list[cnt:]\n",
    "            break\n",
    "\n",
    "outpath = outpath[:-4] + str(int(outpath[-5]) + 1) + str(\".pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                                                            | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image shape (16777216,)\n",
      "unique value [0 1 2 3 4 5 6 7]\n",
      "Start MASKING==================================================\n",
      "Dumping 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      " 50%|██████████████████████████████████████████                                          | 1/2 [00:33<00:33, 33.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image shape (16777216,)\n",
      "unique value [0 1 2 3 4 5 6 7]\n",
      "Start MASKING==================================================\n",
      "Dumping 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [01:14<00:00, 35.60s/it]\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(outpath,\"wb\") as f:\n",
    "    pickler = pickle.Pickler(f)\n",
    "    for  record in tqdm(todolist):\n",
    "\n",
    "        try :\n",
    "\n",
    "            file_name = record['name']\n",
    "            img_fname = record['image']\n",
    "            label_fname = record['label']\n",
    "\n",
    "\n",
    "\n",
    "            # nii load // 이 결과가가 원래 결과랑 같은 지 확인 하자\n",
    "            img = nii_loader(ct_set,img_fname)\n",
    "            lab = nii_loader(ct_set, label_fname)\n",
    "\n",
    "\n",
    "            img = pad3d(img.get_data())\n",
    "            img = image_preprocess(img,new_size=256)\n",
    "\n",
    "            lab = pad3d(lab.get_data())\n",
    "            lab = image_preprocess(lab,new_size=256,mask=True)\n",
    "\n",
    "\n",
    "\n",
    "            print(\"Start MASKING\"+\"=====\"*10)\n",
    "\n",
    "            List = {'filename':file_name,'image': img, 'label':  lab}\n",
    "            pickler.dump(List)\n",
    "\n",
    "            del file_name, img_fname, label_fname, img, lab\n",
    "            \n",
    "            print(\"Dumping\",cnt)\n",
    "            cnt += 1\n",
    "\n",
    "        except MemoryError:\n",
    "            print(\"Memory Error\")\n",
    "            todolist = total_list[cnt:]\n",
    "            break\n",
    "\n",
    "outpath = outpath[:-4] + str(int(outpath[-4]) + 1) + str(\".pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "dict_keys(['filename', 'image', 'label'])\n",
      "(256, 256, 256, 1)\n",
      "img shape: (256, 256, 256, 1), img_raw shape: 134217728\n",
      "annotation_ shape: (256, 256, 256, 8), annotation_raw shape: 536870912\n",
      "1\n",
      "dict_keys(['filename', 'image', 'label'])\n",
      "(256, 256, 256, 1)\n",
      "img shape: (256, 256, 256, 1), img_raw shape: 134217728\n",
      "annotation_ shape: (256, 256, 256, 8), annotation_raw shape: 536870912\n",
      "2\n",
      "dict_keys(['filename', 'image', 'label'])\n",
      "(256, 256, 256, 1)\n",
      "img shape: (256, 256, 256, 1), img_raw shape: 134217728\n",
      "annotation_ shape: (256, 256, 256, 8), annotation_raw shape: 536870912\n",
      "3\n",
      "dict_keys(['filename', 'image', 'label'])\n",
      "(256, 256, 256, 1)\n",
      "img shape: (256, 256, 256, 1), img_raw shape: 134217728\n",
      "annotation_ shape: (256, 256, 256, 8), annotation_raw shape: 536870912\n",
      "4\n",
      "dict_keys(['filename', 'image', 'label'])\n",
      "(256, 256, 256, 1)\n",
      "img shape: (256, 256, 256, 1), img_raw shape: 134217728\n",
      "annotation_ shape: (256, 256, 256, 8), annotation_raw shape: 536870912\n",
      "5\n",
      "dict_keys(['filename', 'image', 'label'])\n",
      "(256, 256, 256, 1)\n",
      "img shape: (256, 256, 256, 1), img_raw shape: 134217728\n",
      "annotation_ shape: (256, 256, 256, 8), annotation_raw shape: 536870912\n",
      "6\n",
      "dict_keys(['filename', 'image', 'label'])\n",
      "(256, 256, 256, 1)\n",
      "img shape: (256, 256, 256, 1), img_raw shape: 134217728\n",
      "annotation_ shape: (256, 256, 256, 8), annotation_raw shape: 536870912\n",
      "7\n",
      "dict_keys(['filename', 'image', 'label'])\n",
      "(256, 256, 256, 1)\n",
      "img shape: (256, 256, 256, 1), img_raw shape: 134217728\n",
      "annotation_ shape: (256, 256, 256, 8), annotation_raw shape: 536870912\n",
      "8\n",
      "dict_keys(['filename', 'image', 'label'])\n",
      "(256, 256, 256, 1)\n",
      "img shape: (256, 256, 256, 1), img_raw shape: 134217728\n",
      "annotation_ shape: (256, 256, 256, 8), annotation_raw shape: 536870912\n",
      "pickle generator created\n",
      "0\n",
      "dict_keys(['filename', 'image', 'label'])\n",
      "(256, 256, 256, 1)\n",
      "img shape: (256, 256, 256, 1), img_raw shape: 134217728\n",
      "annotation_ shape: (256, 256, 256, 8), annotation_raw shape: 536870912\n",
      "1\n",
      "dict_keys(['filename', 'image', 'label'])\n",
      "(256, 256, 256, 1)\n",
      "img shape: (256, 256, 256, 1), img_raw shape: 134217728\n",
      "annotation_ shape: (256, 256, 256, 8), annotation_raw shape: 536870912\n",
      "2\n",
      "dict_keys(['filename', 'image', 'label'])\n",
      "(256, 256, 256, 1)\n",
      "img shape: (256, 256, 256, 1), img_raw shape: 134217728\n",
      "annotation_ shape: (256, 256, 256, 8), annotation_raw shape: 536870912\n",
      "3\n",
      "dict_keys(['filename', 'image', 'label'])\n",
      "(256, 256, 256, 1)\n",
      "img shape: (256, 256, 256, 1), img_raw shape: 134217728\n",
      "annotation_ shape: (256, 256, 256, 8), annotation_raw shape: 536870912\n",
      "4\n",
      "dict_keys(['filename', 'image', 'label'])\n",
      "(256, 256, 256, 1)\n",
      "img shape: (256, 256, 256, 1), img_raw shape: 134217728\n",
      "annotation_ shape: (256, 256, 256, 8), annotation_raw shape: 536870912\n",
      "5\n",
      "dict_keys(['filename', 'image', 'label'])\n",
      "(256, 256, 256, 1)\n",
      "img shape: (256, 256, 256, 1), img_raw shape: 134217728\n",
      "annotation_ shape: (256, 256, 256, 8), annotation_raw shape: 536870912\n",
      "6\n",
      "dict_keys(['filename', 'image', 'label'])\n",
      "(256, 256, 256, 1)\n",
      "img shape: (256, 256, 256, 1), img_raw shape: 134217728\n",
      "annotation_ shape: (256, 256, 256, 8), annotation_raw shape: 536870912\n",
      "7\n",
      "dict_keys(['filename', 'image', 'label'])\n",
      "(256, 256, 256, 1)\n",
      "img shape: (256, 256, 256, 1), img_raw shape: 134217728\n",
      "annotation_ shape: (256, 256, 256, 8), annotation_raw shape: 536870912\n",
      "8\n",
      "dict_keys(['filename', 'image', 'label'])\n",
      "(256, 256, 256, 1)\n",
      "img shape: (256, 256, 256, 1), img_raw shape: 134217728\n",
      "annotation_ shape: (256, 256, 256, 8), annotation_raw shape: 536870912\n",
      "pickle generator created\n",
      "0\n",
      "dict_keys(['filename', 'image', 'label'])\n",
      "(256, 256, 256, 1)\n",
      "img shape: (256, 256, 256, 1), img_raw shape: 134217728\n",
      "annotation_ shape: (256, 256, 256, 8), annotation_raw shape: 536870912\n",
      "1\n",
      "dict_keys(['filename', 'image', 'label'])\n",
      "(256, 256, 256, 1)\n",
      "img shape: (256, 256, 256, 1), img_raw shape: 134217728\n",
      "annotation_ shape: (256, 256, 256, 8), annotation_raw shape: 536870912\n",
      "pickle generator created\n"
     ]
    }
   ],
   "source": [
    "pkl_itr1 = pickle_iter(r'D:\\segmentiation\\scipy_pickle_test0.pkl')\n",
    "pkl_itr2 = pickle_iter(r'D:\\segmentiation\\scipy_pickle_test1.pkl')\n",
    "pkl_itr3 = pickle_iter(r'D:\\segmentiation\\scipy_pickle_test2.pkl')\n",
    "\n",
    "pkl_itr_list = [pkl_itr1, pkl_itr2, pkl_itr3]\n",
    "\n",
    "tfrecords_filename = r\"D:\\segmentiation\\scipy_tfrecord_compression.tfrecord\"\n",
    "write_image_annotation_pairs_to_tfrecord_from_listitr(pkl_itr_list, tfrecords_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\segmentiation\\\\scipy_pickle_test2.pkl'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pkl_itr3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pickle file 모으기\n",
    "## tfrecord itr 돌리기\n",
    "import re \n",
    "p = re.compile('.pkl')\n",
    "\n",
    "path = r\"D:\\segmentiation\"\n",
    "filename_list = ['scipy_pickle_test0.pkl','scipy_pickle_test1.pkl','scipy_pickle_test2.pkl']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-72-6cc53234dfec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mflist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: expected string or bytes-like object"
     ]
    }
   ],
   "source": [
    "p.findall(flist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\segmentiation\\\\scipy_pickle_test1.pkl'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outpath = outpath[:-4] + str(int(outpath[-4]) + 1) + str(\".pkl\")\n",
    "outpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outpath[-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\segmentiation\\\\scipy_pickle_test'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outpath[:-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for record in tqdm(total_list):\n",
    "\n",
    "    file_name = record['name']\n",
    "    img_fname = record['image']\n",
    "    label_fname = record['label']\n",
    "\n",
    "            # nii load // 이 결과가가 원래 결과랑 같은 지 확인 하자\n",
    "    img = nii_loader(ct_set,img_fname)\n",
    "    lab = nii_loader(ct_set, label_fname)\n",
    "    \n",
    "    preprocessed_image = image_preprocess_by_record(img)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'iter_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-47-5680a811b89f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtfrecords_filename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mr\"D:\\segmentiation\\scipy_tfrecord_compression.tfrecord\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mwrite_image_annotation_pairs_to_tfrecord_from_listitr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miter_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtfrecords_filename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'iter_list' is not defined"
     ]
    }
   ],
   "source": [
    "tfrecords_filename = r\"D:\\segmentiation\\scipy_tfrecord_compression.tfrecord\"\n",
    "write_image_annotation_pairs_to_tfrecord_from_listitr(iter_list, tfrecords_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
